{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MY5-Kb1Ma57W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2OVbFRQya1Em"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import string\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import shutil\n",
        "# Define the size of the image\n",
        "IMAGE_WIDTH = 72\n",
        "IMAGE_HEIGHT = 72\n",
        "\n",
        "# Define the path to the Thai font file\n",
        "THAI_FONT_FILE = \"Sarun's_ThangLuang.ttf\"\n",
        "# Define the characters to be included in the dataset\n",
        "CHARACTERS = ''.join([\n",
        "    '0123456789',  # Numbers\n",
        "    'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮ'  # Thai characters\n",
        "])\n",
        "\n",
        "# Define the number of images to be generated for each character\n",
        "NUM_IMAGES_PER_CHARACTER = 10\n",
        "\n",
        "# Define the output directory for the dataset\n",
        "OUTPUT_DIR = 'dataset/'\n",
        "\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "# Load the Thai font\n",
        "font = ImageFont.truetype(THAI_FONT_FILE, IMAGE_WIDTH)\n",
        "\n",
        "# Generate the images\n",
        "for char in CHARACTERS:\n",
        "    if not os.path.exists(OUTPUT_DIR+char):\n",
        "        os.makedirs(OUTPUT_DIR+char)\n",
        "    for i in range(NUM_IMAGES_PER_CHARACTER):\n",
        "        # Create a new image\n",
        "        image = Image.new('L', (IMAGE_WIDTH, IMAGE_HEIGHT), color=255)\n",
        "        \n",
        "        # Draw the character on the image\n",
        "        draw = ImageDraw.Draw(image)\n",
        "        draw.text((20, -50), char, fill=0, font=font)\n",
        "        \n",
        "        # Add noise to the image\n",
        "        image_array = np.array(image)\n",
        "        noise = np.random.normal(0, 10, size=(IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "        image_array = np.clip(image_array + noise, 0, 255).astype(np.uint8)\n",
        "        image = Image.fromarray(image_array)\n",
        "        \n",
        "        # Save the image\n",
        "        filename = f'{char} ({i}).jpg'\n",
        "        filepath = os.path.join(OUTPUT_DIR+char, filename)\n",
        "        image.save(filepath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-4gQ1Fw12Tn",
        "outputId": "6a142efd-3f97-4733-93f3-1bef1dd006c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1278 images belonging to 56 classes.\n",
            "Found 306 images belonging to 56 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\Users\\uSEr\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:1446: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import image_dataset_from_directory, to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "import numpy as np\n",
        "import os, random, tensorflow as tf\n",
        "\n",
        "def set_seed(seed_value=1234):\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    tf.random.set_seed(seed_value)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "\n",
        "set_seed(1234)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    brightness_range=(0.2,0.8),\n",
        "    shear_range=0.2,\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=True,  # apply ZCA whitening\n",
        "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False,\n",
        "    validation_split=0.2)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
        "\n",
        "train = datagen.flow_from_directory('dataset', subset=\"training\", color_mode = 'grayscale',batch_size=20, seed=1234,target_size=(72, 72))\n",
        "val = test_datagen.flow_from_directory('dataset',subset=\"validation\", color_mode = 'grayscale',batch_size=20, seed=1234,target_size=(72, 72))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "num_classes = len(train.class_indices)\n",
        "\n",
        "labels = dict((v,k) for k,v in train.class_indices.items())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms4d-rhLazof",
        "outputId": "c3577eff-2f1c-4563-963d-61b84e2f4c1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 36, 36, 32)        832       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 36, 36, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 32)        25632     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 8, 8, 32)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 56)                28728     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 56)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,104,280\n",
            "Trainable params: 1,104,280\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "<keras.preprocessing.image.DirectoryIterator object at 0x000001DA17813C70>\n",
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\Users\\uSEr\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n",
            "C:\\Users\\uSEr\\AppData\\Local\\Temp\\ipykernel_2716\\1962533041.py:31: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model_1.fit_generator(generator=train,\n",
            "e:\\Users\\uSEr\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:1863: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n",
            "e:\\Users\\uSEr\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:1886: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 4s 36ms/step - loss: 4.0104 - accuracy: 0.0127 - val_loss: 3.9551 - val_accuracy: 0.0233\n",
            "Epoch 2/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 3.9843 - accuracy: 0.0151 - val_loss: 3.9946 - val_accuracy: 0.0200\n",
            "Epoch 3/150\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 3.9541 - accuracy: 0.0270 - val_loss: 3.9029 - val_accuracy: 0.0233\n",
            "Epoch 4/150\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 3.9026 - accuracy: 0.0318 - val_loss: 3.8076 - val_accuracy: 0.0333\n",
            "Epoch 5/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 3.8358 - accuracy: 0.0548 - val_loss: 3.7724 - val_accuracy: 0.0400\n",
            "Epoch 6/150\n",
            "63/63 [==============================] - 3s 46ms/step - loss: 3.7401 - accuracy: 0.0564 - val_loss: 3.6302 - val_accuracy: 0.0867\n",
            "Epoch 7/150\n",
            "63/63 [==============================] - 2s 37ms/step - loss: 3.6001 - accuracy: 0.0754 - val_loss: 3.5829 - val_accuracy: 0.0933\n",
            "Epoch 8/150\n",
            "63/63 [==============================] - 2s 36ms/step - loss: 3.5091 - accuracy: 0.0890 - val_loss: 3.5026 - val_accuracy: 0.0900\n",
            "Epoch 9/150\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 3.3992 - accuracy: 0.1073 - val_loss: 3.3942 - val_accuracy: 0.1300\n",
            "Epoch 10/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 3.3152 - accuracy: 0.1184 - val_loss: 3.3590 - val_accuracy: 0.1300\n",
            "Epoch 11/150\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 3.1891 - accuracy: 0.1638 - val_loss: 3.3143 - val_accuracy: 0.1200\n",
            "Epoch 12/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 3.1059 - accuracy: 0.1566 - val_loss: 3.2015 - val_accuracy: 0.1567\n",
            "Epoch 13/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 3.0522 - accuracy: 0.1765 - val_loss: 3.2129 - val_accuracy: 0.1800\n",
            "Epoch 14/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 2.9647 - accuracy: 0.1995 - val_loss: 3.1334 - val_accuracy: 0.1600\n",
            "Epoch 15/150\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 2.9224 - accuracy: 0.1948 - val_loss: 3.0566 - val_accuracy: 0.1767\n",
            "Epoch 16/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 2.7784 - accuracy: 0.2393 - val_loss: 2.9928 - val_accuracy: 0.2267\n",
            "Epoch 17/150\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 2.7026 - accuracy: 0.2528 - val_loss: 3.0691 - val_accuracy: 0.1833\n",
            "Epoch 18/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 2.6562 - accuracy: 0.2536 - val_loss: 3.0229 - val_accuracy: 0.1967\n",
            "Epoch 19/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 2.6105 - accuracy: 0.2623 - val_loss: 2.9272 - val_accuracy: 0.1967\n",
            "Epoch 20/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 2.5733 - accuracy: 0.2687 - val_loss: 2.9118 - val_accuracy: 0.1900\n",
            "Epoch 21/150\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 2.5611 - accuracy: 0.2639 - val_loss: 2.9166 - val_accuracy: 0.2233\n",
            "Epoch 22/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 2.5133 - accuracy: 0.2758 - val_loss: 2.8270 - val_accuracy: 0.2167\n",
            "Epoch 23/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 2.4270 - accuracy: 0.2997 - val_loss: 2.8332 - val_accuracy: 0.2333\n",
            "Epoch 24/150\n",
            "63/63 [==============================] - 2s 37ms/step - loss: 2.4153 - accuracy: 0.2957 - val_loss: 2.9116 - val_accuracy: 0.2100\n",
            "Epoch 25/150\n",
            "63/63 [==============================] - 2s 39ms/step - loss: 2.3802 - accuracy: 0.2862 - val_loss: 2.7783 - val_accuracy: 0.2367\n",
            "Epoch 26/150\n",
            "63/63 [==============================] - 2s 36ms/step - loss: 2.3440 - accuracy: 0.3283 - val_loss: 2.7552 - val_accuracy: 0.2467\n",
            "Epoch 27/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 2.3200 - accuracy: 0.3426 - val_loss: 2.7223 - val_accuracy: 0.2467\n",
            "Epoch 28/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 2.2667 - accuracy: 0.3593 - val_loss: 2.8348 - val_accuracy: 0.2333\n",
            "Epoch 29/150\n",
            "63/63 [==============================] - 2s 36ms/step - loss: 2.2014 - accuracy: 0.3561 - val_loss: 2.8399 - val_accuracy: 0.2600\n",
            "Epoch 30/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 2.2337 - accuracy: 0.3514 - val_loss: 2.7375 - val_accuracy: 0.2700\n",
            "Epoch 31/150\n",
            "63/63 [==============================] - 2s 38ms/step - loss: 2.1845 - accuracy: 0.3569 - val_loss: 2.6848 - val_accuracy: 0.2733\n",
            "Epoch 32/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 2.1186 - accuracy: 0.3816 - val_loss: 2.6867 - val_accuracy: 0.2600\n",
            "Epoch 33/150\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 2.0796 - accuracy: 0.3887 - val_loss: 2.7017 - val_accuracy: 0.2700\n",
            "Epoch 34/150\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 2.0489 - accuracy: 0.3990 - val_loss: 2.7420 - val_accuracy: 0.2533\n",
            "Epoch 35/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 2.0356 - accuracy: 0.4197 - val_loss: 2.5991 - val_accuracy: 0.2867\n",
            "Epoch 36/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 2.0214 - accuracy: 0.4110 - val_loss: 2.6904 - val_accuracy: 0.2633\n",
            "Epoch 37/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 2.0237 - accuracy: 0.4157 - val_loss: 2.6863 - val_accuracy: 0.2900\n",
            "Epoch 38/150\n",
            "63/63 [==============================] - 2s 37ms/step - loss: 2.0284 - accuracy: 0.3943 - val_loss: 2.5263 - val_accuracy: 0.2900\n",
            "Epoch 39/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 1.9395 - accuracy: 0.4356 - val_loss: 2.5605 - val_accuracy: 0.2933\n",
            "Epoch 40/150\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 1.9172 - accuracy: 0.4332 - val_loss: 2.6355 - val_accuracy: 0.3067\n",
            "Epoch 41/150\n",
            "63/63 [==============================] - 2s 36ms/step - loss: 1.8361 - accuracy: 0.4746 - val_loss: 2.5046 - val_accuracy: 0.3233\n",
            "Epoch 42/150\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.8529 - accuracy: 0.4539 - val_loss: 2.5435 - val_accuracy: 0.2867\n",
            "Epoch 43/150\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.8408 - accuracy: 0.4507 - val_loss: 2.4614 - val_accuracy: 0.3233\n",
            "Epoch 44/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 1.8308 - accuracy: 0.4666 - val_loss: 2.6373 - val_accuracy: 0.2967\n",
            "Epoch 45/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.8305 - accuracy: 0.4547 - val_loss: 2.4748 - val_accuracy: 0.3267\n",
            "Epoch 46/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 1.8751 - accuracy: 0.4483 - val_loss: 2.4436 - val_accuracy: 0.3167\n",
            "Epoch 47/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 1.8121 - accuracy: 0.4666 - val_loss: 2.5113 - val_accuracy: 0.3133\n",
            "Epoch 48/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 1.7794 - accuracy: 0.4603 - val_loss: 2.5799 - val_accuracy: 0.3033\n",
            "Epoch 49/150\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.7499 - accuracy: 0.4650 - val_loss: 2.5873 - val_accuracy: 0.3233\n",
            "Epoch 50/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.6864 - accuracy: 0.4809 - val_loss: 2.3998 - val_accuracy: 0.3133\n",
            "Epoch 51/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.7155 - accuracy: 0.4801 - val_loss: 2.4469 - val_accuracy: 0.3400\n",
            "Epoch 52/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.7003 - accuracy: 0.5087 - val_loss: 2.3900 - val_accuracy: 0.3400\n",
            "Epoch 53/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.7168 - accuracy: 0.4825 - val_loss: 2.3166 - val_accuracy: 0.3633\n",
            "Epoch 54/150\n",
            "63/63 [==============================] - 2s 38ms/step - loss: 1.6633 - accuracy: 0.5119 - val_loss: 2.5181 - val_accuracy: 0.3100\n",
            "Epoch 55/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.6486 - accuracy: 0.5048 - val_loss: 2.3669 - val_accuracy: 0.3333\n",
            "Epoch 56/150\n",
            "63/63 [==============================] - 2s 36ms/step - loss: 1.6281 - accuracy: 0.5270 - val_loss: 2.4258 - val_accuracy: 0.3500\n",
            "Epoch 57/150\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 1.6194 - accuracy: 0.5135 - val_loss: 2.5381 - val_accuracy: 0.3367\n",
            "Epoch 58/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.6094 - accuracy: 0.5079 - val_loss: 2.3380 - val_accuracy: 0.3467\n",
            "Epoch 59/150\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 1.5528 - accuracy: 0.5382 - val_loss: 2.3687 - val_accuracy: 0.3400\n",
            "Epoch 60/150\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 1.5833 - accuracy: 0.5183 - val_loss: 2.4661 - val_accuracy: 0.3267\n",
            "Epoch 61/150\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 1.5499 - accuracy: 0.5175 - val_loss: 2.3884 - val_accuracy: 0.3533\n",
            "Epoch 62/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 1.5631 - accuracy: 0.5207 - val_loss: 2.3314 - val_accuracy: 0.3500\n",
            "Epoch 63/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.5922 - accuracy: 0.5207 - val_loss: 2.3303 - val_accuracy: 0.3600\n",
            "Epoch 64/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.5428 - accuracy: 0.5318 - val_loss: 2.2808 - val_accuracy: 0.3400\n",
            "Epoch 65/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.5159 - accuracy: 0.5413 - val_loss: 2.3144 - val_accuracy: 0.3900\n",
            "Epoch 66/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 1.4973 - accuracy: 0.5429 - val_loss: 2.2627 - val_accuracy: 0.3600\n",
            "Epoch 67/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 1.5236 - accuracy: 0.5612 - val_loss: 2.2301 - val_accuracy: 0.3700\n",
            "Epoch 68/150\n",
            "63/63 [==============================] - 3s 37ms/step - loss: 1.5540 - accuracy: 0.5350 - val_loss: 2.2934 - val_accuracy: 0.3367\n",
            "Epoch 69/150\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 1.4860 - accuracy: 0.5485 - val_loss: 2.3524 - val_accuracy: 0.3567\n",
            "Epoch 70/150\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 1.4806 - accuracy: 0.5572 - val_loss: 2.2512 - val_accuracy: 0.3733\n",
            "Epoch 71/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 1.4482 - accuracy: 0.5556 - val_loss: 2.3862 - val_accuracy: 0.3567\n",
            "Epoch 72/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 1.4678 - accuracy: 0.5541 - val_loss: 2.2404 - val_accuracy: 0.3667\n",
            "Epoch 73/150\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 1.4293 - accuracy: 0.5652 - val_loss: 2.5507 - val_accuracy: 0.3300\n",
            "Epoch 74/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 1.4251 - accuracy: 0.5795 - val_loss: 2.2492 - val_accuracy: 0.3767\n",
            "Epoch 75/150\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 1.4317 - accuracy: 0.5779 - val_loss: 2.3742 - val_accuracy: 0.3767\n",
            "Epoch 76/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 1.3572 - accuracy: 0.5811 - val_loss: 2.5067 - val_accuracy: 0.3400\n",
            "Epoch 77/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 1.4401 - accuracy: 0.5564 - val_loss: 2.3417 - val_accuracy: 0.3667\n",
            "Epoch 78/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.3677 - accuracy: 0.5835 - val_loss: 2.3569 - val_accuracy: 0.3833\n",
            "Epoch 79/150\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 1.4017 - accuracy: 0.5898 - val_loss: 2.2915 - val_accuracy: 0.3800\n",
            "Epoch 80/150\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.3666 - accuracy: 0.5843 - val_loss: 2.3270 - val_accuracy: 0.3700\n",
            "Epoch 81/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 1.4046 - accuracy: 0.5644 - val_loss: 2.2183 - val_accuracy: 0.3833\n",
            "Epoch 82/150\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 1.3625 - accuracy: 0.5882 - val_loss: 2.3063 - val_accuracy: 0.3433\n",
            "Epoch 83/150\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 1.3644 - accuracy: 0.6002 - val_loss: 2.2543 - val_accuracy: 0.3733\n",
            "Epoch 84/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 1.3538 - accuracy: 0.5906 - val_loss: 2.4386 - val_accuracy: 0.3700\n",
            "Epoch 85/150\n",
            "63/63 [==============================] - 2s 37ms/step - loss: 1.3559 - accuracy: 0.6010 - val_loss: 2.1812 - val_accuracy: 0.4000\n",
            "Epoch 86/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 1.3320 - accuracy: 0.5827 - val_loss: 2.1519 - val_accuracy: 0.4000\n",
            "Epoch 87/150\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 1.3424 - accuracy: 0.5906 - val_loss: 2.2420 - val_accuracy: 0.4000\n",
            "Epoch 88/150\n",
            "63/63 [==============================] - 3s 46ms/step - loss: 1.3367 - accuracy: 0.5906 - val_loss: 2.0925 - val_accuracy: 0.4100\n",
            "Epoch 89/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.3555 - accuracy: 0.6033 - val_loss: 2.3112 - val_accuracy: 0.3900\n",
            "Epoch 90/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 1.3468 - accuracy: 0.6017 - val_loss: 2.1308 - val_accuracy: 0.4033\n",
            "Epoch 91/150\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 1.3198 - accuracy: 0.5898 - val_loss: 2.1162 - val_accuracy: 0.4033\n",
            "Epoch 92/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.3092 - accuracy: 0.5922 - val_loss: 2.1922 - val_accuracy: 0.3767\n",
            "Epoch 93/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 1.2882 - accuracy: 0.5827 - val_loss: 2.3774 - val_accuracy: 0.3900\n",
            "Epoch 94/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 1.2948 - accuracy: 0.6033 - val_loss: 2.3374 - val_accuracy: 0.3567\n",
            "Epoch 95/150\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.3167 - accuracy: 0.6025 - val_loss: 2.2638 - val_accuracy: 0.3600\n",
            "Epoch 96/150\n",
            "63/63 [==============================] - 2s 36ms/step - loss: 1.2625 - accuracy: 0.6129 - val_loss: 2.0748 - val_accuracy: 0.3867\n",
            "Epoch 97/150\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.2893 - accuracy: 0.6057 - val_loss: 2.1415 - val_accuracy: 0.4000\n",
            "Epoch 98/150\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.2347 - accuracy: 0.6161 - val_loss: 2.3296 - val_accuracy: 0.3500\n",
            "Epoch 99/150\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 1.2813 - accuracy: 0.6033 - val_loss: 2.0666 - val_accuracy: 0.4300\n",
            "Epoch 100/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 1.2600 - accuracy: 0.6017 - val_loss: 2.1170 - val_accuracy: 0.4300\n",
            "Epoch 101/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 1.2419 - accuracy: 0.6200 - val_loss: 2.1268 - val_accuracy: 0.4000\n",
            "Epoch 102/150\n",
            "63/63 [==============================] - 2s 38ms/step - loss: 1.2488 - accuracy: 0.5954 - val_loss: 2.1487 - val_accuracy: 0.3967\n",
            "Epoch 103/150\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 1.2153 - accuracy: 0.6391 - val_loss: 2.1924 - val_accuracy: 0.3667\n",
            "Epoch 104/150\n",
            "63/63 [==============================] - 2s 39ms/step - loss: 1.2330 - accuracy: 0.6153 - val_loss: 2.0904 - val_accuracy: 0.3933\n",
            "Epoch 105/150\n",
            "63/63 [==============================] - 2s 36ms/step - loss: 1.2471 - accuracy: 0.6161 - val_loss: 2.0646 - val_accuracy: 0.3867\n",
            "Epoch 106/150\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 1.2327 - accuracy: 0.6264 - val_loss: 2.3185 - val_accuracy: 0.3600\n",
            "Epoch 107/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 1.2105 - accuracy: 0.6429 - val_loss: 2.1368 - val_accuracy: 0.4300\n",
            "Epoch 108/150\n",
            "63/63 [==============================] - 2s 38ms/step - loss: 1.2126 - accuracy: 0.6343 - val_loss: 2.0499 - val_accuracy: 0.4367\n",
            "Epoch 109/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 1.2276 - accuracy: 0.6208 - val_loss: 2.0407 - val_accuracy: 0.4167\n",
            "Epoch 110/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.1743 - accuracy: 0.6335 - val_loss: 2.0335 - val_accuracy: 0.4233\n",
            "Epoch 111/150\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 1.2103 - accuracy: 0.6296 - val_loss: 2.3301 - val_accuracy: 0.4100\n",
            "Epoch 112/150\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 1.1981 - accuracy: 0.6415 - val_loss: 2.1332 - val_accuracy: 0.3933\n",
            "Epoch 113/150\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 1.2255 - accuracy: 0.6248 - val_loss: 2.2415 - val_accuracy: 0.3667\n",
            "Epoch 114/150\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 1.1273 - accuracy: 0.6526 - val_loss: 2.2203 - val_accuracy: 0.3800\n",
            "Epoch 115/150\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 1.1607 - accuracy: 0.6367 - val_loss: 2.1736 - val_accuracy: 0.4133\n",
            "Epoch 116/150\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 1.1797 - accuracy: 0.6240 - val_loss: 2.0995 - val_accuracy: 0.4067\n",
            "Epoch 117/150\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 1.2130 - accuracy: 0.6288 - val_loss: 2.2625 - val_accuracy: 0.3967\n",
            "Epoch 118/150\n",
            "63/63 [==============================] - 2s 27ms/step - loss: 1.1635 - accuracy: 0.6455 - val_loss: 2.0262 - val_accuracy: 0.4300\n",
            "Epoch 119/150\n",
            "63/63 [==============================] - 2s 27ms/step - loss: 1.1580 - accuracy: 0.6479 - val_loss: 2.3030 - val_accuracy: 0.3700\n",
            "Epoch 120/150\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 1.1967 - accuracy: 0.6192 - val_loss: 2.1134 - val_accuracy: 0.4367\n",
            "Epoch 121/150\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 1.1159 - accuracy: 0.6518 - val_loss: 2.0642 - val_accuracy: 0.4200\n",
            "Epoch 122/150\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 1.2358 - accuracy: 0.6296 - val_loss: 2.0579 - val_accuracy: 0.4233\n",
            "Epoch 123/150\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 1.0865 - accuracy: 0.6447 - val_loss: 2.0625 - val_accuracy: 0.4167\n",
            "Epoch 124/150\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 1.0857 - accuracy: 0.6630 - val_loss: 2.1089 - val_accuracy: 0.4367\n",
            "Epoch 125/150\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 1.1880 - accuracy: 0.6415 - val_loss: 2.0396 - val_accuracy: 0.4367\n",
            "Epoch 126/150\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 1.1765 - accuracy: 0.6391 - val_loss: 2.0508 - val_accuracy: 0.4533\n",
            "Epoch 127/150\n",
            "63/63 [==============================] - 2s 27ms/step - loss: 1.1073 - accuracy: 0.6399 - val_loss: 2.0402 - val_accuracy: 0.4533\n",
            "Epoch 128/150\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 1.1537 - accuracy: 0.6486 - val_loss: 2.1268 - val_accuracy: 0.4033\n",
            "Epoch 129/150\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 1.1593 - accuracy: 0.6455 - val_loss: 2.1272 - val_accuracy: 0.3767\n",
            "Epoch 130/150\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 1.1063 - accuracy: 0.6677 - val_loss: 2.1424 - val_accuracy: 0.4367\n",
            "Epoch 131/150\n",
            "63/63 [==============================] - 2s 27ms/step - loss: 1.1453 - accuracy: 0.6590 - val_loss: 2.0474 - val_accuracy: 0.4600\n",
            "Epoch 132/150\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 1.1157 - accuracy: 0.6447 - val_loss: 1.9825 - val_accuracy: 0.4333\n",
            "Epoch 133/150\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 1.1212 - accuracy: 0.6542 - val_loss: 2.1601 - val_accuracy: 0.4100\n",
            "Epoch 134/150\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 1.1241 - accuracy: 0.6717 - val_loss: 2.2084 - val_accuracy: 0.4067\n",
            "Epoch 135/150\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 1.1389 - accuracy: 0.6479 - val_loss: 2.1720 - val_accuracy: 0.4333\n",
            "Epoch 136/150\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 1.0867 - accuracy: 0.6622 - val_loss: 2.0441 - val_accuracy: 0.4367\n",
            "Epoch 137/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 1.1622 - accuracy: 0.6645 - val_loss: 2.0272 - val_accuracy: 0.4433\n",
            "Epoch 138/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 1.0847 - accuracy: 0.6789 - val_loss: 2.0369 - val_accuracy: 0.4333\n",
            "Epoch 139/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.1035 - accuracy: 0.6574 - val_loss: 2.0679 - val_accuracy: 0.4400\n",
            "Epoch 140/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.0928 - accuracy: 0.6598 - val_loss: 2.0846 - val_accuracy: 0.4333\n",
            "Epoch 141/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.0757 - accuracy: 0.6638 - val_loss: 2.0081 - val_accuracy: 0.4267\n",
            "Epoch 142/150\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 1.0820 - accuracy: 0.6542 - val_loss: 2.1040 - val_accuracy: 0.4600\n",
            "Epoch 143/150\n",
            "63/63 [==============================] - 2s 37ms/step - loss: 1.1100 - accuracy: 0.6685 - val_loss: 1.9775 - val_accuracy: 0.4667\n",
            "Epoch 144/150\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 1.0790 - accuracy: 0.6669 - val_loss: 1.9173 - val_accuracy: 0.4700\n",
            "Epoch 145/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 1.1408 - accuracy: 0.6526 - val_loss: 2.0327 - val_accuracy: 0.4133\n",
            "Epoch 146/150\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 1.0622 - accuracy: 0.6661 - val_loss: 1.9915 - val_accuracy: 0.4500\n",
            "Epoch 147/150\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 1.0842 - accuracy: 0.6614 - val_loss: 2.1319 - val_accuracy: 0.4433\n",
            "Epoch 148/150\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 1.0453 - accuracy: 0.6693 - val_loss: 2.0418 - val_accuracy: 0.3967\n",
            "Epoch 149/150\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 1.0300 - accuracy: 0.6757 - val_loss: 2.0480 - val_accuracy: 0.4267\n",
            "Epoch 150/150\n",
            "63/63 [==============================] - 3s 40ms/step - loss: 1.0985 - accuracy: 0.6757 - val_loss: 2.3094 - val_accuracy: 0.3833\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "model_1 = Sequential()\n",
        "\n",
        "\n",
        "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
        "                 input_shape=(72,72,1)))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(Dropout(0.25))\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(512))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(num_classes))\n",
        "model_1.add(Activation('softmax'))\n",
        "\n",
        "model_1.summary()\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(lr=0.0005, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model_1.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "print(train)\n",
        "STEP_SIZE_TRAIN=train.n//train.batch_size\n",
        "STEP_SIZE_VALID=val.n//val.batch_size\n",
        "model_1.fit_generator(generator=train,\n",
        "            steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "            epochs=150,\n",
        "            validation_steps=STEP_SIZE_VALID,\n",
        "            validation_data=val)\n",
        "\n",
        "model_1.save('OCR.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "jV1CeUjzX9fb",
        "outputId": "394df82b-c6de-4f02-f501-7b65565d0f1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "142\n",
            "1/1 [==============================] - 1s 540ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Vehicle plate: ฌ5ฦส592\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import imutils\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "import functools\n",
        "import numpy as np\n",
        "\n",
        "original_image = cv2.imread('image9.jpg')\n",
        "#cv2.imshow('image',original_image)\n",
        "\n",
        "original_image = imutils.resize(original_image, width=500 )\n",
        "gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY) \n",
        "gray_image = cv2.bilateralFilter(gray_image, 11, 17, 17)\n",
        "\n",
        "#cv2.imshow('image',original_image)\n",
        "#cv2.imshow('image',gray_image)\n",
        "\n",
        "edged_image = cv2.Canny(gray_image, 10, 200)\n",
        "#cv2.imshow('image',edged_image)\n",
        "\n",
        "\n",
        "contours, new = cv2.findContours(edged_image.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "img1 = original_image.copy()\n",
        "cv2.drawContours(img1, contours, -1, (0, 0,255), 3)\n",
        "#cv2.imshow('image',img1)\n",
        "print(len(contours))\n",
        "\n",
        "\n",
        "contours = sorted(contours, key = cv2.contourArea, reverse = True)[:100]\n",
        "screenCnt = None\n",
        "img2 = original_image.copy()\n",
        "\n",
        "cv2.drawContours(img2, contours, -1, (0, 0,255), 3)\n",
        "#cv2.imshow('image',img2)\n",
        "\n",
        "count = 0\n",
        "idx = 7\n",
        "\n",
        "for c in contours :\n",
        "    contour_perimeter = cv2.arcLength(c, True)\n",
        "    approx = cv2.approxPolyDP(c, 0.018 * contour_perimeter, True)\n",
        "\n",
        "    if len(approx) == 4:\n",
        "        screenCnt = approx\n",
        "        x, y, w, h = cv2.boundingRect(c)\n",
        "        new_img = original_image [ y: y + h, x: x + w]\n",
        "        cv2.imwrite('cropped.png',new_img)\n",
        "        idx += 1\n",
        "        break\n",
        "        \n",
        "cv2.drawContours(original_image , [screenCnt], -1, (0, 0,255), 3)\n",
        "#cv2.imshow('image',original_image )\n",
        "\n",
        "\n",
        "cropped_License_Plate = 'cropped.png' \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "image = cv2.imread(cropped_License_Plate)\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "thresh = cv2.adaptiveThreshold(blurred, 255,\n",
        "    cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 45, 15)\n",
        "\n",
        "\n",
        "_, labels = cv2.connectedComponents(thresh)\n",
        "mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
        "\n",
        "\n",
        "total_pixels = image.shape[0] * image.shape[1]\n",
        "lower = total_pixels // 70 \n",
        "upper = total_pixels // 20 \n",
        "\n",
        "\n",
        "for (i, label) in enumerate(np.unique(labels)):\n",
        "\n",
        "    if label == 0:\n",
        "        continue\n",
        " \n",
        "\n",
        "    labelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
        "    labelMask[labels == label] = 255\n",
        "    numPixels = cv2.countNonZero(labelMask)\n",
        " \n",
        "\n",
        "    if numPixels > lower and numPixels < upper:\n",
        "        mask = cv2.add(mask, labelMask)\n",
        "        \n",
        "\n",
        "cnts, _ = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
        "\n",
        "\n",
        "def compare(rect1, rect2):\n",
        "    if abs(rect1[1] - rect2[1]) > 10:\n",
        "        return rect1[1] - rect2[1]\n",
        "    else:\n",
        "        return rect1[0] - rect2[0]\n",
        "boundingBoxes = sorted(boundingBoxes, key=functools.cmp_to_key(compare) )\n",
        "\n",
        "\n",
        "TARGET_WIDTH = 72\n",
        "TARGET_HEIGHT = 72\n",
        "chars = ''.join([\n",
        "    '0123456789',\n",
        "    'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮ' \n",
        "])\n",
        "model = load_model('OCR.h5')\n",
        "\n",
        "vehicle_plate = \"\"\n",
        "\n",
        "for rect in boundingBoxes:\n",
        "\n",
        "    x,y,w,h = rect\n",
        "\n",
        "    crop = mask[y:y+h, x:x+w]\n",
        "    crop = cv2.bitwise_not(crop)\n",
        "\n",
        "    rows = crop.shape[0]\n",
        "    columns = crop.shape[1]\n",
        "    paddingY = (TARGET_HEIGHT - rows) // 2 if rows < TARGET_HEIGHT else int(0.17 * rows)\n",
        "    paddingX = (TARGET_WIDTH - columns) // 2 if columns < TARGET_WIDTH else int(0.45 * columns)\n",
        "    \n",
        "\n",
        "    crop = cv2.copyMakeBorder(crop, paddingY, paddingY, paddingX, paddingX, cv2.BORDER_CONSTANT, None, 255)\n",
        "\n",
        "    crop = cv2.resize(crop, (TARGET_WIDTH, TARGET_HEIGHT))\n",
        "    cv2.imshow('a',crop)\n",
        "\n",
        "    crop = crop.astype(\"float\") / 255.0\n",
        "    crop = img_to_array(crop)\n",
        "    crop = np.expand_dims(crop, axis=0)\n",
        "\n",
        "    prob = model.predict(crop)[0]\n",
        "    idx = np.argsort(prob)[-1]\n",
        "    vehicle_plate += chars[idx]\n",
        "\n",
        "    cv2.rectangle(image, (x,y), (x+w,y+h), (0, 255, 0), 2)\n",
        "    \n",
        "# Show final image\n",
        "cv2.imshow('a',image)\n",
        "print(\"Vehicle plate: \" + vehicle_plate)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
